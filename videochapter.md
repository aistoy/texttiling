# 视频内容主题分段：一种结合图社区检测与大语言模型（LLM）的混合解决方案

## 1. 方案概述

本方案旨在为**基于ASR转录文本的视频内容主题分段**任务提供一个高准确性、高鲁棒性且兼具效率的完整解决方案。方案的核心思想是采用一种**两阶段-精炼 (Two-Stage Refinement)** 的混合架构，将高效的无监督算法与强大的大语言模型（LLM）相结合，让各部分组件发挥其最大优势。

*   **阶段一：候选边界生成**：利用先进的图社区检测算法，快速、低成本地从完整的转录文本中筛选出所有**潜在的**主题边界点。此阶段追求**高召回率（High Recall）**。
*   **阶段二：智能验证与精炼**：利用大语言模型（LLM）的深度上下文理解和推理能力，对候选边界点进行逐一审核和裁决，去除伪边界。此阶段追求**高精确率（High Precision）**。

这种设计避免了单独使用传统算法时对词汇重叠的敏感性，也避免了单独使用LLM处理长文本时的高成本、速度慢和上下文窗口限制等问题。

## 2. 方案架构图

```
+--------------------------+
|  ASR转录文本             |
| (含时间戳、说话人ID)    |
+--------------------------+
            |
            v
+-------------------------------------------------------------+
| **阶段一：候选边界生成 (Candidate Generation)**               |
|   1. 句子嵌入 (Sentence-BERT)                             |
|   2. 构建相似度图 (Graph Construction)                      |
|   3. 图社区检测 (Louvain Method)                          |
|   4. 后处理，生成候选边界点列表                           |
+-------------------------------------------------------------+
            |
            v
+-------------------------------------------------------------+
| **候选边界档案 (Candidate Profiles)**                       |
|   - 边界点前后局部上下文                                  |
|   - 说话人变化信息                                        |
|   - 时间戳                                                |
+-------------------------------------------------------------+
            |
            v
+-------------------------------------------------------------+
| **阶段二：智能验证与精炼 (Intelligent Verification)**       |
|   1. 设计高效Prompt (含思维链和结构化输出)                  |
|   2. 调用LLM API进行“是/否”裁决                           |
|   3. 解析LLM输出，确认最终边界点                          |
+-------------------------------------------------------------+
            |
            v
+--------------------------+
|  最终主题分段结果         |
|  (JSON格式，含时间、文本) |
+--------------------------+
```

## 3. 阶段一：候选边界生成

此阶段的目标是高效地识别出所有潜在的主题边界。我们采用受[《Text Tiling Done Right》](https://towardsdatascience.com/text-tiling-done-right-building-solid-foundations-for-your-personal-llm-e70947779ac1/)启发的先进图社区检测方法。

### 3.1. 实现步骤

1.  **文本预处理与嵌入 (Preprocessing & Embedding)**
    *   **单元化**：将ASR转录文本按句子（或话语）切分为独立的文本单元。每个单元必须关联其开始/结束时间戳和说话人ID。
    *   **句子嵌入**：使用强大的句子嵌入模型（推荐 **Sentence-BERT**，如 `paraphrase-MiniLM-L6-v2`）将每个文本单元转换为一个高维语义向量。

2.  **构建相似度图 (Graph Construction)**
    *   创建一个图，其中每个句子是一个**节点 (Node)**。
    *   对于每个句子节点 `i`，将其与后续的 `K` 个句子（例如 `K=5`）连接成**边 (Edge)**。
    *   边的**权重 (Weight)** 由两部分相乘得到：
        *   **语义相似度**：句子 `i` 和句子 `j` 向量的余弦相似度。**注意：必须将 `[-1, 1]` 的余弦相似度映射到 `[0, 1]` 区间（例如 `(score + 1) / 2`），以避免负权重。**
        *   **距离惩罚**：一个随距离 `l` 指数衰减的权重，如 `exp(-l/2)`，体现了越近的句子关系越紧密的先验知识。

3.  **图社区检测 (Community Detection)**
    *   在构建好的加权图上，运行 **Louvain Method** 社区发现算法。
    *   该算法能自动找到图中连接最紧密的句子簇（社区），每个社区就代表了一个连贯的主题块。

4.  **后处理与输出 (Post-processing & Output)**
    *   **紧凑化**：处理社区检测可能产生的非连续块（例如一个社区包含句子1,2,5），确保最终的段落是时间上连续的。
    *   **生成候选点**：每个社区（除第一个外）的起始句子的索引，即被视为一个候选边界点。
    *   **输出**：生成一个“候选边界档案”列表，供阶段二使用。

## 4. 阶段二：智能验证与精炼

此阶段利用LLM对候选边界进行精准裁决。

### 4.1. 输入上下文策略

这是一个关键决策，我们推荐以下优先级：

1.  **推荐方案：局部上下文 (Local Context)**
    *   **操作**：只输入边界点前后的N句话（例如，N=5）。
    *   **理由**：成本最低、速度最快、信噪比高。足以应对绝大多数“突然”的话题切换。是最佳的起点和默认选项。

2.  **高级方案：摘要+局部上下文 (Summary + Local Context)**
    *   **操作**：先用LLM为边界前后的完整段落生成摘要，然后将“两段摘要”和“局部上下文”一同提供给LLM。
    *   **理由**：能有效解决“渐进式”话题漂移问题，准确性更高，但成本也更高。仅在需要解决此类特定问题时使用。

3.  **不推荐方案：输入完整内容**
    *   **理由**：成本过高、速度极慢，且容易超出主流LLM的上下文窗口限制。

### 4.2. 实现步骤

1.  **准备“决策档案” (Prepare Decision Dossier)**
    根据阶段一的输出，为每个候选点构建一个包含以下信息的Python字典或JSON对象：

    ```json
    {
      "boundary_index": 48,
      "timestamp": "00:12:34",
      "context_before": ["前文第1句...", "前文第2句...", "前文第3句..."],
      "context_after": ["后文第1句...", "后文第2句...", "后文第3句..."],
      "speaker_change": true
    }
    ```

2.  **设计高效Prompt (Prompt Engineering)**
    采用“思维链”(Chain-of-Thought)和结构化输出的Prompt模板，引导LLM进行逻辑推理并保证输出易于解析。

    ```
    你是一位专业的会议纪要分析师，你的任务是判断文本中一个潜在的节点是否是真正的主题切换点。

    **背景信息:**
    - 候选边界点位于“前文”的结尾和“后文”的开头之间。
    - 说话人是否变化: {speaker_change}

    **前文:**
    ---
    {context_before}
    ---

    **后文:**
    ---
    {context_after}
    ---

    **分析任务:**
    1.  **推理 (Reasoning):** 请首先分析“前文”和“后文”在语义、话题和逻辑上是否存在明显的转变。请结合“说话人是否变化”这一重要信息进行综合判断。请将你的推理过程写在<reasoning>标签内。
    2.  **决策 (Decision):** 基于你的推理，明确判断这是否构成一个新主题的开始。请在<decision>标签内，只回答 "YES" 或 "NO"。

    **输出格式:**
    <reasoning>
    你的详细分析写在这里...
    </reasoning>
    <decision>
    YES/NO
    </decision>
    ```

3.  **执行与解析 (Execution & Parsing)**
    *   编写代码循环遍历所有候选档案，填充Prompt模板。
    *   调用LLM API（推荐`gpt-4-turbo`或`gemini-pro`等高能力模型）。
    *   使用正则表达式 `re.search(r"<decision>(YES|NO)</decision>", response_text)` 来100%准确地解析LLM的最终决策。
    *   只保留LLM决策为 "YES" 的候选点的时间戳。

## 5. 最终输出

将阶段二确认后的时间戳列表作为最终分割点，整理原始转录文本，生成结构化的JSON文件。

```json
[
  {
    "start_time": "00:00:05",
    "end_time": "00:12:33",
    "topic_summary": "Q3财报回顾与增长分析",
    "transcript": "完整的第一个主题段落的文本..."
  },
  {
    "start_time": "00:12:34",
    "end_time": "00:25:10",
    "topic_summary": "海外市场开拓计划",
    "transcript": "完整的第二个主题段落的文本..."
  }
]
```
*(注：`topic_summary` 可作为额外步骤，让LLM对每个确认的文本段落进行总结生成)*

## 6. 技术栈与依赖

```
# requirements.txt

# 核心NLP与文本处理
spacy

# 句子嵌入与LLM调用
transformers
torch
sentence-transformers

# 图计算与社区检测
networkx
python-louvain
scipy

# 数据处理与可选的LLM库
numpy
openai # 或者 google-generativeai 等
```

同时，需要下载Spacy的语言模型：
```bash
python -m spacy download en_core_web_sm
```
